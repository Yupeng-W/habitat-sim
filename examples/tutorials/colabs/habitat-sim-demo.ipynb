{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import habitat_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scene = \"../data/scene_datasets/mp3d_example/17DRP5sb8fy/17DRP5sb8fy.glb\"\n",
    "config_file = \"../data/scene_datasets/mp3d_example/mp3d.scene_dataset_config.json\"\n",
    "\n",
    "sim_settings = {\n",
    "    \"width\": 256,  # Spatial resolution of the observations\n",
    "    \"height\": 256,\n",
    "    \"scene\": test_scene,  # Scene path\n",
    "    \"config_file\": config_file,  # config path\n",
    "    \"default_agent\": 0,\n",
    "    \"sensor_height\": 1.5,  # Height of sensors in meters\n",
    "    \"color_sensor\": True,  # RGB sensor\n",
    "    \"semantic_sensor\": True,  # Semantic sensor\n",
    "    \"depth_sensor\": True,  # Depth sensor\n",
    "    \"seed\": 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulator config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cfg(settings):\n",
    "    sim_cfg = habitat_sim.SimulatorConfiguration()\n",
    "    sim_cfg.gpu_device_id = 0\n",
    "    sim_cfg.scene_id = settings[\"scene\"]\n",
    "    sim_cfg.scene_dataset_config_file = settings[\"config_file\"]\n",
    "\n",
    "    # Note: all sensors must have the same resolution\n",
    "    sensors = {\n",
    "        \"color_sensor\": {\n",
    "            \"sensor_type\": habitat_sim.SensorType.COLOR,\n",
    "            \"resolution\": [settings[\"height\"], settings[\"width\"]],\n",
    "            \"position\": [0.0, settings[\"sensor_height\"], 0.0],\n",
    "        },\n",
    "        \"depth_sensor\": {\n",
    "            \"sensor_type\": habitat_sim.SensorType.DEPTH,\n",
    "            \"resolution\": [settings[\"height\"], settings[\"width\"]],\n",
    "            \"position\": [0.0, settings[\"sensor_height\"], 0.0],\n",
    "        },\n",
    "        \"semantic_sensor\": {\n",
    "            \"sensor_type\": habitat_sim.SensorType.SEMANTIC,\n",
    "            \"resolution\": [settings[\"height\"], settings[\"width\"]],\n",
    "            \"position\": [0.0, settings[\"sensor_height\"], 0.0],\n",
    "        },\n",
    "    }\n",
    "\n",
    "    sensor_specs = []\n",
    "    for sensor_uuid, sensor_params in sensors.items():\n",
    "        if settings[sensor_uuid]:\n",
    "            sensor_spec = habitat_sim.CameraSensorSpec()\n",
    "            sensor_spec.uuid = sensor_uuid\n",
    "            sensor_spec.sensor_type = sensor_params[\"sensor_type\"]\n",
    "            sensor_spec.resolution = sensor_params[\"resolution\"]\n",
    "            sensor_spec.position = sensor_params[\"position\"]\n",
    "\n",
    "            sensor_specs.append(sensor_spec)\n",
    "\n",
    "    # Here you can specify the amount of displacement in a forward action and the turn angle\n",
    "    agent_cfg = habitat_sim.agent.AgentConfiguration()\n",
    "    agent_cfg.sensor_specifications = sensor_specs\n",
    "    agent_cfg.action_space = {\n",
    "        \"move_forward\": habitat_sim.agent.ActionSpec(\n",
    "            \"move_forward\", habitat_sim.agent.ActuationSpec(amount=0.25)\n",
    "        ),\n",
    "        \"turn_left\": habitat_sim.agent.ActionSpec(\n",
    "            \"turn_left\", habitat_sim.agent.ActuationSpec(amount=30.0)\n",
    "        ),\n",
    "        \"turn_right\": habitat_sim.agent.ActionSpec(\n",
    "            \"turn_right\", habitat_sim.agent.ActuationSpec(amount=30.0)\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    return habitat_sim.Configuration(sim_cfg, [agent_cfg])\n",
    "\n",
    "\n",
    "cfg = make_cfg(sim_settings)\n",
    "sim = habitat_sim.Simulator(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scene semantic annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_scene_recur(scene, limit_output=10):\n",
    "    print(\n",
    "        f\"House has {len(scene.levels)} levels, {len(scene.regions)} regions and {len(scene.objects)} objects\"\n",
    "    )\n",
    "    print(f\"House center:{scene.aabb.center} dims:{scene.aabb.sizes}\")\n",
    "\n",
    "    count = 0\n",
    "    for level in scene.levels:\n",
    "        print(\n",
    "            f\"Level id:{level.id}, center:{level.aabb.center},\"\n",
    "            f\" dims:{level.aabb.sizes}\"\n",
    "        )\n",
    "        for region in level.regions:\n",
    "            print(\n",
    "                f\"Region id:{region.id}, category:{region.category.name()},\"\n",
    "                f\" center:{region.aabb.center}, dims:{region.aabb.sizes}\"\n",
    "            )\n",
    "            for obj in region.objects:\n",
    "                print(\n",
    "                    f\"Object id:{obj.id}, category:{obj.category.name()},\"\n",
    "                    f\" center:{obj.aabb.center}, dims:{obj.aabb.sizes}\"\n",
    "                )\n",
    "                count += 1\n",
    "                if count >= limit_output:\n",
    "                    return\n",
    "\n",
    "\n",
    "# Print semantic annotation information (id, category, bounding box details)\n",
    "# about levels, regions and objects in a hierarchical fashion\n",
    "scene = sim.semantic_scene\n",
    "print_scene_recur(scene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(sim_settings[\"seed\"])\n",
    "sim.seed(sim_settings[\"seed\"])\n",
    "\n",
    "# Set agent state\n",
    "agent = sim.initialize_agent(sim_settings[\"default_agent\"])\n",
    "agent_state = habitat_sim.AgentState()\n",
    "agent_state.position = np.array([0.0, 0.072447, 0.0])\n",
    "agent.set_state(agent_state)\n",
    "\n",
    "# Get agent state\n",
    "agent_state = agent.get_state()\n",
    "print(\"agent_state: position\", agent_state.position, \"rotation\", agent_state.rotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "from habitat_sim.utils.viz_utils import d3_40_colors_rgb\n",
    "\n",
    "\n",
    "def display_sample(rgb_obs, semantic_obs, depth_obs):\n",
    "    rgb_img = Image.fromarray(rgb_obs, mode=\"RGBA\")\n",
    "\n",
    "    semantic_img = Image.new(\"P\", (semantic_obs.shape[1], semantic_obs.shape[0]))\n",
    "    semantic_img.putpalette(d3_40_colors_rgb.flatten())\n",
    "    semantic_img.putdata((semantic_obs.flatten() % 40).astype(np.uint8))\n",
    "    semantic_img = semantic_img.convert(\"RGBA\")\n",
    "\n",
    "    depth_img = Image.fromarray((depth_obs / 10 * 255).astype(np.uint8), mode=\"L\")\n",
    "\n",
    "    arr = [rgb_img, semantic_img, depth_img]\n",
    "    titles = [\"rgb\", \"semantic\", \"depth\"]\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for i, data in enumerate(arr):\n",
    "        ax = plt.subplot(1, 3, i + 1)\n",
    "        ax.axis(\"off\")\n",
    "        ax.set_title(titles[i])\n",
    "        plt.imshow(data)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take random actions and display sensor data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_frames = 0\n",
    "action_names = list(cfg.agents[sim_settings[\"default_agent\"]].action_space.keys())\n",
    "\n",
    "max_frames = 5\n",
    "\n",
    "while total_frames < max_frames:\n",
    "    action = random.choice(action_names)\n",
    "    print(\"action\", action)\n",
    "    observations = sim.step(action)\n",
    "    rgb = observations[\"color_sensor\"]\n",
    "    semantic = observations[\"semantic_sensor\"]\n",
    "    depth = observations[\"depth_sensor\"]\n",
    "\n",
    "    display_sample(rgb, semantic, depth)\n",
    "\n",
    "    total_frames += 1"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "nb_python//py:percent,colabs//ipynb",
   "notebook_metadata_filter": "all"
  },
  "kernelspec": {
   "display_name": "habitat-conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15 (default, Nov 24 2022, 12:02:37) \n[Clang 14.0.6 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "bc610832847940db8f914271584cded827abd6a574c2f47f11661201ec9782a4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
